[config]
root = ~/model/openpose-pytorch

[image]
# 368
# 344
# 320
size = 320 320

[cache]
name = cache
; config/dataset/person18_19
; config/dataset/person14_13
dataset = config/dataset/person14_13
shuffle = 1
mask_ext = .jpg

[model]
name = model
; model.dnn.vgg.person18_19
; model.dnn.resnet.resnet18
; model.dnn.inception3.Inception3
; model.dnn.inception4.Inception4
; model.dnn.inception4.Inception4_down3_4
; model.dnn.mobilenet.MobileNet
; model.dnn.mobilenet2.MobileNet2
; model.dnn.densenet.densenet121
dnn = model.dnn.mobilenet2.MobileNet2
# model.stages.openpose.Stage0 model.stages.openpose.Stage model.stages.openpose.Stage model.stages.openpose.Stage model.stages.openpose.Stage model.stages.openpose.Stage
# model.stages.unet.Unet1Sqz3 model.stages.unet.Unet1Sqz3_a
# model.stages.unet.Unet2Sqz3 model.stages.unet.Unet2Sqz3
stages = model.stages.unet.Unet1Sqz3 model.stages.unet.Unet1Sqz3_a
pretrained = 0

[batch_norm]
enable = 0
gamma = 1
beta = 1

[inception4]
pretrained = imagenet

[data]
workers = 3
sizes = 320,320
maintain = 10
shuffle = 0
# fixed rescale
resize = fixed

[transform]
; transform.augmentation.RandomRotate transform.augmentation.RandomFlipHorizontally
augmentation = transform.augmentation.RandomRotate transform.augmentation.RandomFlipHorizontally
resize_train = transform.resize.label.RandomCrop
resize_eval = transform.resize.label.Resize
resize_test = transform.resize.image.Resize
; transform.image.RandomBlur transform.image.BGR2HSV transform.image.RandomHue transform.image.RandomSaturation transform.image.RandomBrightness transform.image.HSV2RGB transform.image.RandomGamma
image_train = transform.image.BGR2RGB
image_test = transform.image.BGR2RGB
; torchvision.transforms.ToTensor transform.image.Normalize
tensor = torchvision.transforms.ToTensor transform.image.Normalize
normalize = 0.5 1

[augmentation]
random_rotate = -40 40
random_flip_horizontally = 0.5
random_crop = 1.5 2
random_blur = 5 5
random_hue = 0 25
random_saturation = 0.5 1.5
random_brightness = 0.5 1.5
random_gamma = 0.9 1.5

[label]
sigma_parts = 7
sigma_limbs = 1

[train]
; lambda params, lr: torch.optim.SGD(params, lr, momentum=2)
; lambda params, lr: torch.optim.Adam(params, lr, betas=(0.9, 0.999), eps=1e-8)
; lambda params, lr: torch.optim.RMSprop(params, lr, alpha=0.99, eps=1e-8)
optimizer = lambda params, lr: torch.optim.Adam(params, lr, betas=(0.9, 0.999), eps=1e-8)
; lambda optimizer: torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)
; lambda optimizer: torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 90], gamma=0.1)
scheduler = lambda optimizer: torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 90], gamma=0.1)
phase = train val
cross_entropy = 1
clip_ = 5

[save]
secs = 600
keep = 5

[draw_points]
colors = r w

[summary]
scalar = 10
image = 60
histogram_ = 60

[summary_scalar]
loss_hparam = 0

[summary_image]
limit = 2
data_keypoints = 1
data_parts = 1
data_limbs = 1
estimate = 1
output = parts limbs
stage = -1

[summary_histogram]
parameters = config/summary/histogram.txt

[hparam]
parts = 1
limbs = 1

[estimate]
interpolation = cubic

[nms]
threshold = 0.05

[integration]
step = 5
step_limits = 5 25
min_score = 0.05
min_count = 9

[cluster]
min_score = 0.4
min_count = 3

[eval]
phase = test
secs = 12 * 60 * 60
first = 0
iou = 0.5
db = eval.json
mapper = config/eval.py
debug = 0
sort = timestamp
metric07 = 1

[graph]
metric = lambda t: np.mean(utils.dense(t))
format = svg

[digraph_graph_attr]
size = 12, 12

[digraph_node_attr]
style = filled
shape = box
align = left
fontsize = 12
ranksep = 0.1
height = 0.2
